{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88898f60",
   "metadata": {},
   "source": [
    "### Logistic Regression Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484011b4",
   "metadata": {},
   "source": [
    "In this section, we implement a logistic regression classifier to predict whether an individual is obese or non-obese using the provided dataset. \n",
    "\n",
    "All data handling, training, and evaluation steps are encapsulated in a single Python class for modularity and easy integration with the project’s architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716ee54b",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "To prepare the data for modeling, we perform several steps:\n",
    "\n",
    "* Data Loading & Cleaning:\n",
    "\n",
    " Read the CSV dataset (detailed_meals_macros_.csv) into a pandas DataFrame. Use the DataCleaner class (from the Data_Preprocessing module) to drop duplicate entries, remove rows with missing values, and normalize column names (strip whitespace, replace spaces with underscores, and convert to lowercase for consistency).\n",
    "\n",
    "* Feature Engineering: \n",
    "\n",
    " Leverage the DataPreprocessor class (from Data_Preprocessing) to create additional features.We convert height from centimeters to meters and calculate the BMI for each individual. An obesity label is then derived based on gender-specific BMI thresholds (e.g., BMI ≥ 30 for males, BMI ≥ 25 for females are labeled obese). This label is stored in a new column (e.g., obesity with values 1 for obese and 0 for non-obese).\n",
    "\n",
    "\n",
    "* Encoding Categorical Variables: \n",
    "\n",
    " Categorical features such as activity level and dietary preference are label-encoded to numeric values using scikit-learn’s LabelEncoder. Gender is already handled in the obesity feature creation (mapped to 0/1), so it is treated as numeric.\n",
    "\n",
    "* Feature Selection: \n",
    "\n",
    " We drop irrelevant or non-numeric columns that won’t be used in modeling. In particular, textual columns like meal suggestions (breakfast_suggestion, lunch_suggestion, dinner_suggestion, snack_suggestion) and the disease column are removed. These columns contain free-text or goal descriptions that are not directly usable by the model. We also drop the original height and weight features since BMI (which we keep as a feature) already captures the relationship between height and weight for obesity classification. This helps reduce redundancy and multicollinearity in our feature set.\n",
    "\n",
    "* Normalization:\n",
    "\n",
    " All remaining feature columns (which are now numeric) are normalized using StandardScaler to ensure they are on a similar scale. This step improves the logistic regression model’s convergence and performance. The scaled feature matrix and the target vector are prepared for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677e5820",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation\n",
    "\n",
    "With the data preprocessed, we proceed to model training and evaluation:\n",
    "\n",
    "1) Train-Test Split:\n",
    "\n",
    "    The clean and engineered dataset is split into training and testing subsets (for example, 75% train and 25% test) using scikit-learn’s train_test_split (via the data_split utility in Data_Loader). We stratify the split on the obesity label to maintain the same proportion of obese vs. non-obese in both sets.\n",
    "\n",
    "\n",
    "2) Logistic Regression Model:\n",
    "\n",
    "   We initialize a scikit-learn LogisticRegression classifier and train (fit) it on the training data. Default parameters (such as an L2 penalty and an appropriate solver) are used, but these can be adjusted if needed. The training process learns the weights for each feature in order to best separate obese vs. non-obese individuals.\n",
    "\n",
    "3) Prediction:\n",
    "\n",
    "   After training, we use the model to predict labels on the test set. These predictions are then compared to the true labels to evaluate performance.\n",
    "\n",
    "4) Evaluation Metrics:\n",
    "\n",
    "   We compute key classification metrics: accuracy (the fraction of correct predictions), the confusion matrix (to see counts of true positives, true negatives, false positives, false negatives), and the classification report (which includes precision, recall, and F1-score for each class) on the test data. These metrics provide a comprehensive overview of how well the model is performing in classifying individuals as obese or non-obese.\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24d80a9",
   "metadata": {},
   "source": [
    "The entire process is encapsulated in the LogisticRegressionModel class below. This class can be integrated into the larger project (e.g., used within a Jupyter notebook or a Streamlit app) by instantiating it and calling its methods to prepare data, train the model, and retrieve evaluation results."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
