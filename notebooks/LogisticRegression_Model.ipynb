{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88898f60",
   "metadata": {},
   "source": [
    "### Logistic Regression Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484011b4",
   "metadata": {},
   "source": [
    "In this section, we implement a logistic regression classifier to predict whether an individual is obese or non-obese using the provided dataset. \n",
    "\n",
    "All data handling, training, and evaluation steps are encapsulated in a single Python class for modularity and easy integration with the project’s architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716ee54b",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "To prepare the data for modeling, we perform several steps:\n",
    "\n",
    "* Data Loading & Cleaning:\n",
    "\n",
    " Read the CSV dataset (detailed_meals_macros_.csv) into a pandas DataFrame. Use the DataCleaner class (from the Data_Preprocessing module) to drop duplicate entries, remove rows with missing values, and normalize column names (strip whitespace, replace spaces with underscores, and convert to lowercase for consistency).\n",
    "\n",
    "* Feature Engineering: \n",
    "\n",
    " Leverage the DataPreprocessor class (from Data_Preprocessing) to create additional features.We convert height from centimeters to meters and calculate the BMI for each individual. An obesity label is then derived based on gender-specific BMI thresholds (e.g., BMI ≥ 30 for males, BMI ≥ 25 for females are labeled obese). This label is stored in a new column (e.g., obesity with values 1 for obese and 0 for non-obese).\n",
    "\n",
    "\n",
    "* Encoding Categorical Variables: \n",
    "\n",
    " Categorical features such as activity level and dietary preference are label-encoded to numeric values using scikit-learn’s LabelEncoder. Gender is already handled in the obesity feature creation (mapped to 0/1), so it is treated as numeric.\n",
    "\n",
    "* Feature Selection: \n",
    "\n",
    " We drop irrelevant or non-numeric columns that won’t be used in modeling. In particular, textual columns like meal suggestions (breakfast_suggestion, lunch_suggestion, dinner_suggestion, snack_suggestion) and the disease column are removed. These columns contain free-text or goal descriptions that are not directly usable by the model. We also drop the original height and weight features since BMI (which we keep as a feature) already captures the relationship between height and weight for obesity classification. This helps reduce redundancy and multicollinearity in our feature set.\n",
    "\n",
    "* Normalization:\n",
    "\n",
    " All remaining feature columns (which are now numeric) are normalized using StandardScaler to ensure they are on a similar scale. This step improves the logistic regression model’s convergence and performance. The scaled feature matrix and the target vector are prepared for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677e5820",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation\n",
    "\n",
    "With the data preprocessed, we proceed to model training and evaluation:\n",
    "\n",
    "1) Train-Test Split:\n",
    "\n",
    "    The clean and engineered dataset is split into training and testing subsets (for example, 75% train and 25% test) using scikit-learn’s train_test_split (via the data_split utility in Data_Loader). We stratify the split on the obesity label to maintain the same proportion of obese vs. non-obese in both sets.\n",
    "\n",
    "\n",
    "2) Logistic Regression Model:\n",
    "\n",
    "   We initialize a scikit-learn LogisticRegression classifier and train (fit) it on the training data. Default parameters (such as an L2 penalty and an appropriate solver) are used, but these can be adjusted if needed. The training process learns the weights for each feature in order to best separate obese vs. non-obese individuals.\n",
    "\n",
    "3) Prediction:\n",
    "\n",
    "   After training, we use the model to predict labels on the test set. These predictions are then compared to the true labels to evaluate performance.\n",
    "\n",
    "4) Evaluation Metrics:\n",
    "\n",
    "   We compute key classification metrics: accuracy (the fraction of correct predictions), the confusion matrix (to see counts of true positives, true negatives, false positives, false negatives), and the classification report (which includes precision, recall, and F1-score for each class) on the test data. These metrics provide a comprehensive overview of how well the model is performing in classifying individuals as obese or non-obese.\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24d80a9",
   "metadata": {},
   "source": [
    "The entire process is encapsulated in the LogisticRegressionModel class below. This class can be integrated into the larger project (e.g., used within a Jupyter notebook or a Streamlit app) by instantiating it and calling its methods to prepare data, train the model, and retrieve evaluation results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b79c1e",
   "metadata": {},
   "source": [
    "### Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8a4d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757fa929",
   "metadata": {},
   "source": [
    "Now we are ready for main part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0eff28a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel:\n",
    "    \"\"\"\n",
    "    Logistic Regression model for Obese vs Non-Obese classification.\n",
    "\n",
    "    Designed to work cleanly with your current repo structure without requiring:\n",
    "    from Data_Loader... or from Data_Preprocessing...\n",
    "\n",
    "    You can pass a preprocessed df OR let this class load the CSV.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame = None,\n",
    "        data_path: str = \"data/raw/detailed_meals_macros_.csv\",\n",
    "        target_column: str = \"obese\",\n",
    "        test_size: float = 0.2,\n",
    "        random_state: int = 42,\n",
    "        bmi_threshold: float = 30.0,\n",
    "        drop_height_weight_from_X: bool = True\n",
    "    ):\n",
    "        self.df = df\n",
    "        self.data_path = data_path\n",
    "        self.target_column = target_column\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.bmi_threshold = bmi_threshold\n",
    "        self.drop_height_weight_from_X = drop_height_weight_from_X\n",
    "\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "\n",
    "        self.feature_columns_ = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1cb547",
   "metadata": {},
   "source": [
    "Note: We used pipeline method for previous presentation sor we can use again to avoid issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27273859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(self) -> pd.DataFrame:\n",
    "        if self.df is not None:\n",
    "            return self.df.copy()\n",
    "\n",
    "        return pd.read_csv(self.data_path)\n",
    "\n",
    "def _normalize_columns(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # Lowercase + replace spaces with underscores\n",
    "        df = df.copy()\n",
    "        df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
    "\n",
    "        # Handle duplicate-like names such as dinner_protein.1\n",
    "        # Make columns unique if pandas auto-added suffixes\n",
    "        # (safe no-op if already unique)\n",
    "        new_cols = []\n",
    "        seen = {}\n",
    "        for c in df.columns:\n",
    "            if c not in seen:\n",
    "                seen[c] = 0\n",
    "                new_cols.append(c)\n",
    "            else:\n",
    "                seen[c] += 1\n",
    "                new_cols.append(f\"{c}_{seen[c]}\")\n",
    "        df.columns = new_cols\n",
    "\n",
    "        return df\n",
    "\n",
    "def _create_obesity_label(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Creates BMI + obese label if not already present.\n",
    "        Assumes height in cm and weight in kg if available.\n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "\n",
    "        if self.target_column in df.columns:\n",
    "            return df\n",
    "\n",
    "        # Try common column names after normalization\n",
    "        height_col = \"height\"\n",
    "        weight_col = \"weight\"\n",
    "\n",
    "        if height_col in df.columns and weight_col in df.columns:\n",
    "            height_m = df[height_col] / 100.0\n",
    "            bmi = df[weight_col] / (height_m ** 2)\n",
    "\n",
    "            df[\"bmi\"] = bmi\n",
    "            df[self.target_column] = (df[\"bmi\"] >= self.bmi_threshold).astype(int)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Cannot create target '{self.target_column}'. \"\n",
    "                f\"Expected columns '{height_col}' and '{weight_col}' to compute BMI.\"\n",
    "            )\n",
    "\n",
    "        return df\n",
    "\n",
    "def _drop_text_columns(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df.copy()\n",
    "\n",
    "        # Drop any column that looks like suggestion text\n",
    "        drop_cols = [c for c in df.columns if \"suggestion\" in c]\n",
    "        # Your dataset also has a \"disease\" column that looks like goal text\n",
    "        if \"disease\" in df.columns:\n",
    "            drop_cols.append(\"disease\")\n",
    "\n",
    "        existing = [c for c in drop_cols if c in df.columns]\n",
    "        if existing:\n",
    "            df.drop(columns=existing, inplace=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "def _encode_categoricals(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df.copy()\n",
    "\n",
    "        # Identify object columns except target\n",
    "        cat_cols = [\n",
    "            c for c in df.columns\n",
    "            if df[c].dtype == \"object\" and c != self.target_column\n",
    "        ]\n",
    "\n",
    "        if cat_cols:\n",
    "            df = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "def preprocess(self) -> pd.DataFrame:\n",
    "        df = self.load_data()\n",
    "        df = self._normalize_columns(df)\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "        # Basic missing-value handling\n",
    "        # (We’ll do final numeric fill later)\n",
    "        df = df.dropna(subset=[c for c in df.columns if c in [\"height\", \"weight\"]], how=\"any\")\n",
    "\n",
    "        df = self._create_obesity_label(df)\n",
    "        df = self._drop_text_columns(df)\n",
    "        df = self._encode_categoricals(df)\n",
    "\n",
    "        # Optionally remove direct BMI inputs from features to reduce leakage\n",
    "        if self.drop_height_weight_from_X:\n",
    "            for col in [\"height\", \"weight\", \"bmi\"]:\n",
    "                if col in df.columns:\n",
    "                    # keep them in df for reference if you want,\n",
    "                    # but we'll drop from X later in build_features\n",
    "                    pass\n",
    "\n",
    "        # Fill remaining missing numeric with median\n",
    "        for c in df.columns:\n",
    "            if c != self.target_column and pd.api.types.is_numeric_dtype(df[c]):\n",
    "                df[c] = df[c].fillna(df[c].median())\n",
    "\n",
    "        self.df = df\n",
    "        return df\n",
    "\n",
    "def build_features(self):\n",
    "        if self.df is None:\n",
    "            self.preprocess()\n",
    "\n",
    "        df = self.df.copy()\n",
    "\n",
    "        y = df[self.target_column].astype(int)\n",
    "\n",
    "        X = df.drop(columns=[self.target_column])\n",
    "\n",
    "        if self.drop_height_weight_from_X:\n",
    "            for col in [\"height\", \"weight\", \"bmi\"]:\n",
    "                if col in X.columns:\n",
    "                    X = X.drop(columns=[col])\n",
    "\n",
    "        # Keep feature names for later reference\n",
    "        self.feature_columns_ = X.columns.tolist()\n",
    "\n",
    "        return X, y\n",
    "\n",
    "def split_data(self):\n",
    "        X, y = self.build_features()\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y,\n",
    "            test_size=self.test_size,\n",
    "            random_state=self.random_state,\n",
    "            stratify=y\n",
    "        )\n",
    "\n",
    "def build_model(self, C: float = 1.0, max_iter: int = 1000):\n",
    "        if self.X_train is None:\n",
    "            self.split_data()\n",
    "\n",
    "        self.scaler = StandardScaler()\n",
    "        X_train_scaled = self.scaler.fit_transform(self.X_train)\n",
    "        X_test_scaled = self.scaler.transform(self.X_test)\n",
    "\n",
    "        self.model = LogisticRegression(C=C, max_iter=max_iter)\n",
    "        self.model.fit(X_train_scaled, self.y_train)\n",
    "\n",
    "        # Store scaled test for evaluation convenience\n",
    "        self._X_test_scaled = X_test_scaled\n",
    "\n",
    "def evaluate_model(self):\n",
    "        if self.model is None:\n",
    "            self.build_model()\n",
    "\n",
    "        y_pred = self.model.predict(self._X_test_scaled)\n",
    "\n",
    "        acc = accuracy_score(self.y_test, y_pred)\n",
    "        cm = confusion_matrix(self.y_test, y_pred)\n",
    "        report = classification_report(self.y_test, y_pred, target_names=[\"Non-Obese\", \"Obese\"])\n",
    "\n",
    "        return {\n",
    "            \"accuracy\": acc,\n",
    "            \"confusion_matrix\": cm,\n",
    "            \"classification_report\": report\n",
    "        }\n",
    "\n",
    "def get_coefficients(self) -> pd.DataFrame:\n",
    "        if self.model is None or self.feature_columns_ is None:\n",
    "            raise ValueError(\"Train the model before requesting coefficients.\")\n",
    "\n",
    "        coef = self.model.coef_.ravel()\n",
    "        return pd.DataFrame({\n",
    "            \"feature\": self.feature_columns_,\n",
    "            \"coefficient\": coef\n",
    "        }).sort_values(by=\"coefficient\", ascending=False)\n",
    "\n",
    "def predict(self, new_df: pd.DataFrame):\n",
    "        if self.model is None or self.scaler is None:\n",
    "            raise ValueError(\"Train the model before calling predict().\")\n",
    "\n",
    "        tmp = new_df.copy()\n",
    "        tmp = self._normalize_columns(tmp)\n",
    "        tmp = self._drop_text_columns(tmp)\n",
    "        tmp = self._encode_categoricals(tmp)\n",
    "\n",
    "        # Align columns to training features\n",
    "        for col in self.feature_columns_:\n",
    "            if col not in tmp.columns:\n",
    "                tmp[col] = 0\n",
    "\n",
    "        tmp = tmp[self.feature_columns_]\n",
    "\n",
    "        X_scaled = self.scaler.transform(tmp)\n",
    "        return self.model.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b36f63",
   "metadata": {},
   "source": [
    "### Summary and References:\n",
    "\n",
    "In the code above, the LogisticRegressionModel class handles data loading, preprocessing (using the project’s DataCleaner and DataPreprocessor utilities), model training, and evaluation. After instantiating this class and calling build_model(), one can call evaluate_model() to obtain the accuracy, confusion matrix, and classification report for the test data. These metrics will indicate how well the logistic regression model is able to classify individuals as obese or non-obese."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d02494",
   "metadata": {},
   "source": [
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*\n",
    "\n",
    "*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
